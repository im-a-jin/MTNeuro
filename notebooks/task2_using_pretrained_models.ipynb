{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JoMV7mwBJWI"
   },
   "source": [
    "# Running Task 2 with a Pre-Trained Model\n",
    "\n",
    "This notebook walks through an example of utilizing the existing trained models ([pre-trained weights](https://www.dropbox.com/sh/pzza5nuh93r9s18/AAAZsISLUl1H_u3U0TDSeOjNa?dl=0)) to perform pixel-level brain microstructure (blood-vessel, cell, axon) segmentations.\n",
    "\n",
    "## Intro\n",
    "\n",
    "In MTNeuro, we provied multiple tasks to evaluate the model across multiple scales and capabilities. This notebook deals with `Task 2`, .i.e, the **Pixel Level Brain Microstructure Segmentation Task**, and provides methods to download and load the pretrained weights and models configs to easily perform pixel-level segmentation and explore the outcomes.\n",
    "\n",
    "#### Citation\n",
    "For more details about `Task 2` and the other tasks, please refer:\n",
    "\n",
    "```\n",
    "Quesada, J., Sathidevi, L., Liu, R., Ahad, N., Jackson, J.M., Azabou, M., ... & Dyer, E. L. (2022). MTNeuro: A Benchmark for Evaluating Representations of Brain Structure Across Multiple Levels of Abstraction. Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track.\n",
    "\n",
    "Prasad, J. A., Balwani, A. H., Johnson, E. C., Miano, J. D., Sampathkumar, V., De Andrade, V., ... & Dyer, E. L. (2020). A three-dimensional thalamocortical dataset for characterizing brain heterogeneity. Scientific Data, 7(1), 1-7.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50LV7mP7BXUG"
   },
   "source": [
    "### Specifying the Model, Setting, and Mode for Image Segmentation\n",
    "\n",
    "Specify your preferred model and setting in the code below (refer to table below for available options)\n",
    "\n",
    "**Available Options**:\n",
    "\\begin{array} & \\underline{\\textbf{2D Models}} & \\hspace{35pt}\\underline{\\textbf{3D Models}} & \\hspace{35pt}\\underline{\\textbf{Settings}} & \\hspace{35pt}\\underline{\\textbf{Modes}} \\\\  UNet & \\hspace{35pt}UNet & \\hspace{35pt}3class & \\hspace{35pt}3D \\\\ smp\\_UnetPlusPlus & \\hspace{35pt}mzp\\_HighResNet & \\hspace{35pt}4class & \\hspace{35pt}2D \\\\\n",
    "smp\\_PSPNet & \\hspace{35pt}mzp\\_VNetLight & & \\\\\n",
    "smp\\_PAN & & & \\\\\n",
    "smp\\_FPN & & & \\\\\n",
    "smp\\_MAnet\\end{array}\n",
    "\n",
    "\n",
    "Note: `smp` indicates models imported from [segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch) library and `mzp` indicates models imported from [medicalzoopytorch](https://github.com/black0017/MedicalZooPytorch) library.\n",
    "\n",
    "\n",
    "**3class Setting**: Segmentation using 3 labels - cell bodies, blood vessels and background (axons considered as background)\n",
    "\n",
    "**4class Setting**: Segmentation using 4 labels - cell bodies, blood vessels, axons and background. In this setting the ZI region is excluded as clearly distinguishing the axons in the slices from ZI region would be difficult even for a knowledgeable human annotator.\n",
    "\n",
    "_Refer [MTNeuro paper](https://openreview.net/forum?id=5xuowSQ17vy) for more details on the models, tasks and settings._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "X_rFC-9pprOk"
   },
   "outputs": [],
   "source": [
    "Model = 'UNet'         #Eg:- UNet, smp_PAN\n",
    "Setting = '3class'     #Eg:- 3class, 4class\n",
    "Mode = '2D'            #Eg:- 3D, 2D\n",
    "\n",
    "fh = open('config.txt', 'w')\n",
    "fh.write(Model+' '+Setting+' '+Mode)\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloning Required Repositories, Installing Libraries and Dependencies, and Importing Packages\n",
    "\n",
    "Installing required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/MTNeuro/MTNeuro && cd MTNeuro && pip install -e .\n",
    "\n",
    "# Setting up the segmentation_models.pytorch library\n",
    "!pip install segmentation-models-pytorch\n",
    "!pip install torchsummaryX\n",
    "\n",
    "#setting up medicalzoopytorch\n",
    "!git clone https://github.com/black0017/MedicalZooPytorch/ && cd MedicalZooPytorch && mv lib ../. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json as json\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "#pytorch imports\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "#intern library that is used to pull 3D brain volume form BossDB\n",
    "import segmentation_models_pytorch as smp      #SMP library: https://github.com/qubvel/segmentation_models.pytorch; For models and for calculation of metrics\n",
    "import lib.medzoo as medzoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BossDBDataset` class is used to download the required slices of brain imaging data from `BossDB`. Let's import it from the cloned MTNeuro package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BossDB MTNeuro dataset loader\n",
    "from MTNeuro.bossdbdataset import BossDBDataset               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the trained weights and corresponding configuration file\n",
    "\n",
    "The trained weights and configuration files for the models can also be downloaded manually from: [Link](https://www.dropbox.com/sh/pzza5nuh93r9s18/AAAZsISLUl1H_u3U0TDSeOjNa?dl=0). \n",
    "\n",
    "Below script automatically does that for you (using the model and setting specified earlier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n22xtELH1fHV",
    "outputId": "b07859cd-31ed-49a2-f6ab-3b4600c9a873"
   },
   "outputs": [],
   "source": [
    "!bash scripts/download_pretrained_weights_and_conf.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYsbDYK2BgDS"
   },
   "source": [
    "### Loading the appropriate Configuration File\n",
    "\n",
    "**task config**: Settings corresponding to the task, like the x, y and z region of the slices. [Example](https://github.com/MTNeuro/MTNeuro/blob/main/MTNeuro/taskconfig/task2_2D_3class.json)\n",
    "\n",
    "**network config**: Settings corresponding to the model and the training, like model layer sizes, training batch size, etc. [Example](https://github.com/MTNeuro/MTNeuro/blob/main/MTNeuro/networkconfig/UNet_2D_3class.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "0cAm0W6krI8P"
   },
   "outputs": [],
   "source": [
    "#load the task config for specified setting that \n",
    "#(specifies the x,y ranges to pick from the data for forming the slices)\n",
    "task_config = json.load(open('../MTNeuro/taskconfig/task2_'+str(Mode)+'_'+str(Setting)+'.json'))\n",
    "\n",
    "#Load the network config for the specified setting\n",
    "#(Contains the batch size and model config information)\n",
    "network_config = json.load(open(glob.glob(\"*.json\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8snEjb_3Bk_l"
   },
   "source": [
    "### Loading the Model and the corresponding pre-trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the custom `load_model()` method from `loading_model.py` for loading the specified model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a741Xg1_ByPQ"
   },
   "source": [
    "#### Loading the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the device onto which you want load the model and utilize `load_model()` method.\n",
    "\n",
    "**Syntax**: `model_object = load_model(<network configuration file for the model>, <device onto which to load the model>)`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.loading_model import load_model\n",
    "\n",
    "# Specify device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else  torch.device('cpu')\n",
    "\n",
    "model_object = load_model(network_config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g-NVRH0B2HG"
   },
   "source": [
    "#### Loading the pre-trained weights to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom `load_weights()` method loads the downloaded pretrained weights into the specified `model_object`\n",
    "\n",
    "**Syntax**: `model_object = load_weights(<name of the model>, <Mode>, <Setting>, <the object of the actual model>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGUAaEds-zJA"
   },
   "outputs": [],
   "source": [
    "from scripts.load_pretrained_weights import load_weights\n",
    "model_object = load_weights(Model, Mode, Setting, model_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHJ6CNC7Hofc"
   },
   "source": [
    "### Preparing the DataLoader using BossDBDataset\n",
    "\n",
    "**BossDBDataset**: Helper class that utilizes the `intern` library to download 3D brain volume from BossDB and convert it into a suitable PyTorch dataloader of image slices.\n",
    "\n",
    "Note: The `ToTensor` transform needs to be applied in order to enable the conversion from numpy to PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCiSUe-9Hori",
    "outputId": "ec518260-0ae3-43d5-a04f-1d0510dbf2df"
   },
   "outputs": [],
   "source": [
    "##Set-up the test dataloader\n",
    "test_data = BossDBDataset(task_config, None, 'test')\n",
    "\n",
    "#droping last batch due to unequal size\n",
    "if Mode==\"3D\":\n",
    "    test_data = Subset(test_data, list(range(len(test_data))[:-network_config['batch_size']]))\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                                        batch_size=network_config['batch_size'],\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svrM6QLZCVLF"
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iS0QcBMVCYal"
   },
   "source": [
    "#### Prediction Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "5NPWEZni-2m4"
   },
   "outputs": [],
   "source": [
    "#function to predict using trained model\n",
    "def predict(img, model, device):\n",
    "        model.eval()\n",
    "        x = img.to(device)  # to torch, send to device\n",
    "        with torch.no_grad():\n",
    "            out = model(x)  # send through model/network\n",
    "\n",
    "        out_argmax = torch.argmax(out, dim=1)  # perform softmax on outputs\n",
    "        return out_argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzFi3KduHM4k"
   },
   "source": [
    "#### Prediction Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgUtyIkvA2tI"
   },
   "outputs": [],
   "source": [
    "batch_iter = tqdm(enumerate(test_dataloader), 'test', total=len(test_dataloader), leave=False)\n",
    "# predict the segmentations of test set\n",
    "tp_tot = torch.empty(0,network_config['classes'])\n",
    "fp_tot = torch.empty(0,network_config['classes'])\n",
    "fn_tot = torch.empty(0,network_config['classes'])\n",
    "tn_tot = torch.empty(0,network_config['classes'])\n",
    "\n",
    "#specify the device to load the input data to\n",
    "devce = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "y_ = []\n",
    "x_ = []\n",
    "output_ = []\n",
    "for i, (x, y) in batch_iter:\n",
    "    target = y.to(device) #can do this on CPU\n",
    "    y_.append(y)\n",
    "    x_.append(x.squeeze())\n",
    "    with torch.no_grad():\n",
    "        # get the output image (make prediction)\n",
    "        output = predict(x, model_object, device)\n",
    "        output_.append(output)\n",
    "        tp_, fp_, fn_, tn_ = smp.metrics.get_stats(output, target, mode='multiclass', num_classes = network_config['classes'])\n",
    "        tp_tot = torch.vstack((tp_tot,tp_))\n",
    "        fp_tot = torch.vstack((fp_tot,fp_))\n",
    "        fn_tot = torch.vstack((fn_tot,fn_))\n",
    "        tn_tot = torch.vstack((tn_tot,tn_))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f4108ecf01062aca25e5dc86ed0d2b2584059290a9a8508cbbea0875ac6d25a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
