{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting Started: Multi-Task Decoding (Task 3)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MTNeuro/MTNeuro/blob/notebook_cleanup/notebooks/task3_getting_started.ipynb)\n",
    "\n",
    "### We will use the ðŸ”„ icon to indicate places that you can change.",
    "\n",
    "This **MTNeuro** jupyter notebook takes you through how you can execute `task 3`. It takes in an encoder and computes R2 scores between embeddings and different Semantic features.\n",
    "\n",
    "For more details on the tasks and dataset, please refer to our paper:\n",
    "\n",
    "    \"Quesada, J., Sathidevi, L., Liu, R., Ahad, N., Jackson, J.M., Azabou, M., ... & Dyer, E. L. (2022). MTNeuro: A Benchmark for Evaluating Representations of Brain Structure Across Multiple Levels of Abstraction. Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'intern[cloudvolume]' scikit-learn timm pretrainedmodels efficientnet_pytorch segmentation-models-pytorch\n",
    "!git clone https://github.com/MTNeuro/MTNeuro && cd MTNeuro && pip install .\n",
    "%cd MTNeuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import umap\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Sci-kit learn imports\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# MTNeuro modules\n",
    "from MTNeuro.bossdbdataset import BossDBDataset\n",
    "from MTNeuro.annots.features import extract_cell_stats, extract_axon_stats, extract_blood_stats\n",
    "from MTNeuro.annots.get_cutouts import get_cutout_data\n",
    "from MTNeuro.annots.latents import get_latents, get_unsup_latents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Overview\n",
    "![image.png](https://mtneuro.github.io/images/tasks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Description and Task 3 Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Task 3, the \"datasets\" are actually the representations of the models we trained in Task 1! We will use a linear readout on the latent embeddings of the Task 1 models to predict properties of the image such as blood vessels density, cell count and size, axon density and average distance between cells. In order to extract these latents, we will be using the full four cubes specified in task 1 as the training data.\n",
    "\n",
    "In this notebook, we will use the BYOL model [[1]](#1) as the encoder and load in the pretrained weights found here: [[Dropbox]](https://www.dropbox.com/sh/bhmkr6fphyxlils/AAAAcOBSWRoxowGzwu7Tp2LAa?dl=0).\n",
    "\n",
    "<a id=\"1\">[1]</a> Grill, J. B., Strub, F., AltchÃ©, F., Tallec, C., Richemond, P., Buchatskaya, E., ... & Valko, M. (2020). Bootstrap your own latent-a new approach to self-supervised learning. Advances in neural information processing systems, 33, 21271-21284."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data and Model\n",
    "\n",
    "Like with the other tasks, we can load in all the parameters needed to access the data and build the model using the task 3 config file found [here](https://github.com/MTNeuro/MTNeuro/tree/main/MTNeuro/taskconfig).\n",
    "\n",
    "The available encoder types are:\n",
    "- `ssl`: Get the latents from a pretrained BYOL model\n",
    "- `supervised`: Get the latents from a pretrained supervised ResNet model\n",
    "- `PCA`: Get the latents using principal component analysis\n",
    "- `NMF`: Get the latents using non-negative matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be using the ssl encoder type.\n"
     ]
    }
   ],
   "source": [
    "root = \"./MTNeuro/\"\n",
    "\n",
    "## Load the task3 config file\n",
    "with open(os.path.join(root, f\"taskconfig/task3.json\")) as file:\n",
    "    task_config = json.load(file)\n",
    "\n",
    "encoder_type = task_config['encoder_type']\n",
    "encoder_path = task_config['encoder_path']\n",
    "print(\"We will be using the\", encoder_type, \"encoder type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Data\n",
    "\n",
    "We will be using the `BossDBDataset` class to download the training images and their groundtruth annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use transforms.ToTensor() if no other transforms are needed\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "## Since there is no testing for this task, we only load the train data\n",
    "train_data = BossDBDataset(task_config, None, mode='train', image_transform=transform, mask_transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1440 training images.\n"
     ]
    }
   ],
   "source": [
    "## Get a copy of the input images and annotations\n",
    "slices = np.copy(train_data.image_array)\n",
    "annots = np.copy(train_data.mask_array)\n",
    "\n",
    "print(\"We have\", len(slices), \"training images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Pretrained Weights\n",
    "\n",
    "You can download the pretrained weights from the Dropbox link mentioned earlier, but we will use this bash script to automatically download the relevant model weights according to the encoder specified by the task config. The script takes in two arguments: the encoder type and the name of the file to download the weights into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pretrained weights for ssl encoder\n",
      "weights.pt          100%[===================>] 180.33M  10.4MB/s    in 18s     \n"
     ]
    }
   ],
   "source": [
    "!bash notebooks/scripts/download_task3_weights.sh $encoder_type $encoder_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting image properties from groundtruth annotations\n",
    "\n",
    "We can extract properties such as cell, axon, and blood stats using the methods provided by MTNeuro below. These extract methods return a pandas DataFrame where the first column is the image index and the rest are various statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting cell stats...\n",
      "Extracting axon stats...\n",
      "Extracting blood stats...\n"
     ]
    }
   ],
   "source": [
    "print('Extracting cell stats...')\n",
    "stats_cell = extract_cell_stats(annots)\n",
    "\n",
    "print('Extracting axon stats...')\n",
    "stats_axon = extract_axon_stats(annots)\n",
    "\n",
    "print('Extracting blood stats...')\n",
    "stats_blood = extract_blood_stats(annots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of cell stats:  ['Image Number', 'Number of Cells', 'Avg Distance to NN', 'Avg Distance to 3rd NN', 'Avg Cell Size', 'Cell Pixel count']\n",
      "List of axon stats:  ['Image Number', 'Percent of Pixels']\n",
      "List of blood stats:  ['Image Number', 'Percent of Pixels']\n"
     ]
    }
   ],
   "source": [
    "## Print stats for each artifact in the image\n",
    "print(\"List of cell stats: \", list(stats_cell))\n",
    "print(\"List of axon stats: \", list(stats_axon))\n",
    "print(\"List of blood stats: \", list(stats_blood))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract latent embeddings\n",
    "\n",
    "We can extract the latents of self-supervised and supervised models using `get_latents` which takes in the input slices, the path to the pretrained weights, and a boolean value specifying whether the model is self-supervised or supervised. If we are using unsupervised methods, we can use the `get_unsup_latents` function which takes in the input slices and a boolean value for PCA or NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewjin/Downloads/MTNeuro_Notebooks/jupytervenv/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n"
     ]
    }
   ],
   "source": [
    "## Extract latents from the encoder\n",
    "if encoder_type == 'ssl' or encoder_type == 'supervised':\n",
    "    embeddings = get_latents(slices, encoder_path, encoder_type=='ssl')\n",
    "elif encoder_type == 'PCA' or encoder_type == 'NMF':\n",
    "    embeddings = get_unsup_latents(slices, encoder_type=='PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform linear readout\n",
    "\n",
    "We will use sklearn's `LinearRegression` to perform linear readout with the latent embeddings as the training data and the image properties (cell/axon/blood stats) as the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood Vessel Score: 0.8583\n",
      "Cell Count Score: 0.7551\n",
      "Avg Cell Distance Score: 0.5098\n",
      "Cell Size Score: 0.7119\n",
      "Axon Score: 0.9479\n"
     ]
    }
   ],
   "source": [
    "## Get linear readout scores\n",
    "X = embeddings\n",
    "\n",
    "## Predict the percent of blood vessels in the image by pixels\n",
    "y = stats_blood['Percent of Pixels'].to_numpy()\n",
    "reg = LinearRegression().fit(X, y)\n",
    "blood_vsl_score = reg.score(X, y)\n",
    "print(f\"Blood Vessel Score: {blood_vsl_score:.4f}\")\n",
    "\n",
    "## Predict the number of cells in the input image\n",
    "y = stats_cell['Number of Cells'].to_numpy()\n",
    "reg = LinearRegression().fit(X, y)\n",
    "numb_cell = reg.score(X, y)\n",
    "print(f\"Cell Count Score: {numb_cell:.4f}\")\n",
    "\n",
    "## Predict the average distance of a cell to its nearest neighbor\n",
    "y = stats_cell['Avg Distance to NN'].to_numpy()\n",
    "reg = LinearRegression().fit(X, y)\n",
    "avg_dist_nn_cell = reg.score(X, y)\n",
    "print(f\"Avg Cell Distance Score: {avg_dist_nn_cell:.4f}\")\n",
    "\n",
    "## Predict the average cell size\n",
    "y = stats_cell['Avg Cell Size'].to_numpy()\n",
    "reg = LinearRegression().fit(X, y)\n",
    "cell_size = reg.score(X, y)\n",
    "print(f\"Cell Size Score: {cell_size:.4f}\")\n",
    "\n",
    "## Predict the percent of axons in the image by pixels\n",
    "y = stats_axon['Percent of Pixels']\n",
    "reg = LinearRegression().fit(X,y)\n",
    "axon_rslt = reg.score(X, y)\n",
    "print(f\"Axon Score: {axon_rslt:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f4108ecf01062aca25e5dc86ed0d2b2584059290a9a8508cbbea0875ac6d25a"
  },
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
